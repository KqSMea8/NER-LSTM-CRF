{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER训练结果，给定训练和测试文件地址，训练模型，每个epoch存储一份结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from model import BiLSTM_CRF\n",
    "import numpy as np\n",
    "import os, argparse, time, random\n",
    "from utils import str2bool, get_logger, get_entity,get_entity_medical\n",
    "\n",
    "from trainBase import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hypterparameters\n",
    "tf.flags.DEFINE_string('train_data','data_path','train data source')\n",
    "tf.flags.DEFINE_string('test_data', 'data_path', 'test data source')\n",
    "tf.flags.DEFINE_integer('batch_size', 32, 'sample of each minibatch')\n",
    "tf.flags.DEFINE_integer('epoch', 35, 'epoch of traing')\n",
    "tf.flags.DEFINE_integer('hidden_dim', 300, 'dim of hidden state')\n",
    "tf.flags.DEFINE_string('optimizer', 'Adam', 'Adam/Adadelta/Adagrad/RMSProp/Momentum/SG')\n",
    "tf.flags.DEFINE_boolean('CRF',True, 'use CRF at the top layer. if False, use Softmax')\n",
    "tf.flags.DEFINE_float('lr', 0.001, 'learing rate')\n",
    "tf.flags.DEFINE_float('clip', 5.0, 'gradient clipping')\n",
    "tf.flags.DEFINE_float('dropout', 0.5, 'dropout keep_prob')\n",
    "tf.flags.DEFINE_boolean('update_embeddings', True, 'update embeddings during traings')\n",
    "tf.flags.DEFINE_string('pretrain_embedding', 'random', 'use pretrained char embedding or init it randomly')\n",
    "tf.flags.DEFINE_integer('embedding_dim', 300, 'random init char embedding_dim')\n",
    "tf.flags.DEFINE_boolean('shuffle', True, 'shuffle training data before each epoch')\n",
    "tf.flags.DEFINE_string('mode', 'train', 'train/test/demo')\n",
    "tf.flags.DEFINE_string('demo_model', '1516928001', 'model for test and demo')\n",
    "tf.flags.DEFINE_string('wordPath', 'data_path/word', 'train/test/demo')\n",
    "args = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词典映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_word2index, vocabulary_index2word = vocab_build(\"data_path/\", \"data_path/raw2Label.txt\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词嵌入变量的初始化方式 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if args.pretrain_embedding == 'random':\n",
    "    embeddings = random_embedding(vocabulary_word2index, args.embedding_dim)\n",
    "else:\n",
    "    embedding_path = 'pretrain_embedding.npy'\n",
    "    embeddings = np.array(np.load(embedding_path), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load训练和测试数据集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_path/raw2LabelTrain.txt ./data_path/raw2LabelTest.txt\n",
      "9277\n"
     ]
    }
   ],
   "source": [
    "if args.mode != 'demo':\n",
    "    train_path = os.path.join('.', args.train_data,'raw2LabelTrain.txt')\n",
    "    test_path = os.path.join('.', args.test_data, 'raw2LabelTest.txt')\n",
    "    print(train_path, test_path)\n",
    "\n",
    "    train_data = read_corpus(train_path,vocabulary_word2index )\n",
    "    test_data = read_corpus(test_path , vocabulary_word2index)\n",
    "\n",
    "    test_size = len(train_data)\n",
    "    print(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设定存储的日志及模型等地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.platform.flags._FlagValues object at 0x7f4dcfa51320>\n"
     ]
    }
   ],
   "source": [
    "## paths setting\n",
    "timestamp = str(int(time.time())) if args.mode == 'train' else args.demo_model\n",
    "print(\"log dir=\", timestamp)\n",
    "output_path = os.path.join('.', args.train_data+\"_save\", timestamp)\n",
    "if not os.path.exists(output_path): os.makedirs(output_path)\n",
    "summary_path = os.path.join(output_path, \"summaries\")\n",
    "if not os.path.exists(summary_path): os.makedirs(summary_path)\n",
    "model_path = os.path.join(output_path, \"checkpoints/\")\n",
    "if not os.path.exists(model_path): os.makedirs(model_path)\n",
    "ckpt_prefix = os.path.join(model_path, \"model\")\n",
    "result_path = os.path.join(output_path, \"results\")\n",
    "if not os.path.exists(result_path): os.makedirs(result_path)\n",
    "log_path = os.path.join(result_path, \"log.txt\")\n",
    "get_logger(log_path).info(str(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型，迭代epoch次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,train, dev):\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(model.init_op)\n",
    "        model.add_summary(sess)\n",
    "\n",
    "        for epoch in range(model.epoch_num):\n",
    "            run_one_epoch(model, sess, train, dev, model.tag2label, epoch, saver)\n",
    "            model.logger.info(\"========save session========{}\".format(model.model_path))\n",
    "            saver.save(sess, model.model_path, global_step = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========lr==== 0.001\n",
      "self.lr= 0.001\n",
      "embeded_words= (?, ?, 300)\n",
      "biLSTM output= (?, ?, 600)\n",
      "logits= (?, ?, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangxian/tools/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "## training model\n",
    "\n",
    "print(\"==========lr====\", args.lr)\n",
    "model = BiLSTM_CRF(batch_size=args.batch_size, epoch_num=args.epoch, hidden_dim=args.hidden_dim, embeddings=embeddings,\n",
    "                   dropout_keep=args.dropout, optimizer=args.optimizer, lr=args.lr, clip_grad=args.clip,\n",
    "                   tag2label=tag2label, vocab=vocabulary_word2index, shuffle=args.shuffle,\n",
    "                   model_path=ckpt_prefix, summary_path=summary_path, log_path=log_path, result_path=result_path,\n",
    "                   CRF=args.CRF, update_embedding=args.update_embeddings)\n",
    "\n",
    "model.build_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data len= 9277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train lenght=9277 number_batches=290\n",
      "==========1 epoch begin train, time is 2018-05-11 09:16:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing: 1 batch / 290 batches.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-11 09:16:49 epoch 1, step 1, loss: 440.6, global_step: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-11 09:17:48 epoch 1, step 10, loss: 183.5, global_step: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-11 09:18:51 epoch 1, step 20, loss: 158.2, global_step: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-11 09:19:34 epoch 1, step 30, loss: 167.4, global_step: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-11 09:20:30 epoch 1, step 40, loss: 133.7, global_step: 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(\"train data len=\", len(train_data))\n",
    "train(model, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
